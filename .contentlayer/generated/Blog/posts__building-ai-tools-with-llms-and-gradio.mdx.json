{
  "title": "Building AI Tools with LLMs and Gradio",
  "date": "2025-06-18T07:00:00.000Z",
  "tags": [
    "AI",
    "Python"
  ],
  "draft": false,
  "summary": "This project is an AI-powered customer support assistant for a fictional airline called FlightAI. It leverages language models (like GPT-4o-mini) for chat interactions, DALL-E-3 for image generation (e.g., of destination cities), and OpenAI's text-to-speech model for audio responses. The user interface is built with Gradio.",
  "body": {
    "raw": "## Getting Started with LLM Engineering\n\nI've been diving into the world of Large Language Model (LLM) engineering through an excellent [Udemy course](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/) led by industry veteran Ed Donner. This comprehensive program takes you through real-world projects that demonstrate practical applications of AI technology in business scenarios.\n\nCurrently about 25% through the course, I've already had hands-on experience with multiple AI platforms including OpenAI, Anthropic, and locally running models like Ollama. The course covers advanced techniques such as RAG (Retrieval-Augmented Generation), QLoRA (Quantized Low-Rank Adaptation), and AI Agents - all essential tools in the modern AI developer's toolkit.\n\n## The FlightAI Assistant Project\n\nOne of the most engaging projects I completed was the **AI-powered customer support assistant** for a fictional airline called FlightAI. This project perfectly demonstrates how multiple AI services can work together to create a comprehensive user experience.\n\nThe assistant leverages several cutting-edge AI models:\n- **GPT-4o-mini** for natural language chat interactions\n- **DALL-E-3** for generating images of destination cities\n- **OpenAI's TTS-1** for converting text responses to speech\n\nYou can check out the complete project code in my [GitHub repository](https://github.com/ryan-griego/ai-airline-assistant).\n\n## Discovering Gradio for Rapid Prototyping\n\nOne of the most valuable tools introduced in the course is **Gradio**, an open-source Python library that's a game-changer for AI developers. Gradio enables you to quickly build user-friendly web interfaces for AI models, APIs, or any Python function with minimal code.\n\nWhat makes Gradio particularly appealing is its ability to:\n- Create professional-looking demos in minutes\n- Generate live URLs for instant sharing\n- Provide an intuitive interface without requiring web development expertise\n\nThe speed at which you can go from a working AI model to a shareable web application is truly impressive.\n\n## Development Environment and Setup\n\nThe course utilizes a robust development stack:\n- **Anaconda** platform for managing Python environments and dependencies\n- **Jupyter Lab** as the primary development environment for working with notebooks, code, and data\n\nWhile the course materials use Jupyter notebooks, I decided to export my project to a standalone Python file. This approach gave me more flexibility to run the application outside of the Jupyter platform and better understand the underlying code structure.\n\n## Learning About Function Calling with LLMs\n\nOne of the most fascinating concepts I encountered was the ability to extend LLM capabilities through **function calling**. This technique allows the AI model to execute custom functions as part of its response generation process.\n\nIn the airline assistant project, I implemented this by:\n1. Creating custom functions (like `get_ticket_price`)\n2. Passing these functions as tools to the chat completions API\n3. Allowing the LLM to intelligently decide when to call these functions\n\nFor example, when a user asks about ticket prices, the LLM automatically triggers the `get_ticket_price` function, which searches through a dictionary of city names and prices to return accurate pricing information. This seamless integration of custom logic with AI responses creates a much more powerful and practical application.\n\n## Conclusion\n\nThe combination of powerful AI models, intuitive development tools like Gradio, and techniques like function calling opens up endless possibilities for creating practical AI applications.\n\nThe experience of building a multi-modal AI assistant that can chat, generate images, and speak has given me a solid foundation for tackling more complex projects as I continue through the course. I'm excited to explore the remaining 75% of the curriculum and see what other innovative applications I can build.\n\n## Sources\n\n- [AI Airline Assistant GitHub Repo](https://github.com/ryan-griego/ai-airline-assistant)\n- [Udemy Course](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/)\n",
    "code": "var Component=(()=>{var p=Object.create;var l=Object.defineProperty;var g=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var w=(i,n)=>()=>(n||i((n={exports:{}}).exports,n),n.exports),v=(i,n)=>{for(var t in n)l(i,t,{get:n[t],enumerable:!0})},o=(i,n,t,r)=>{if(n&&typeof n==\"object\"||typeof n==\"function\")for(let a of u(n))!f.call(i,a)&&a!==t&&l(i,a,{get:()=>n[a],enumerable:!(r=g(n,a))||r.enumerable});return i};var y=(i,n,t)=>(t=i!=null?p(m(i)):{},o(n||!i||!i.__esModule?l(t,\"default\",{value:i,enumerable:!0}):t,i)),x=i=>o(l({},\"__esModule\",{value:!0}),i);var c=w((k,s)=>{s.exports=_jsx_runtime});var b={};v(b,{default:()=>d,frontmatter:()=>I});var e=y(c()),I={title:\"Building AI Tools with LLMs and Gradio\",date:\"2025-6-18\",tags:[\"AI\",\"Python\"],draft:!1,summary:\"This project is an AI-powered customer support assistant for a fictional airline called FlightAI. It leverages language models (like GPT-4o-mini) for chat interactions, DALL-E-3 for image generation (e.g., of destination cities), and OpenAI's text-to-speech model for audio responses. The user interface is built with Gradio.\"};function h(i){let n={a:\"a\",code:\"code\",h2:\"h2\",li:\"li\",ol:\"ol\",p:\"p\",path:\"path\",span:\"span\",strong:\"strong\",svg:\"svg\",ul:\"ul\",...i.components};return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"getting-started-with-llm-engineering\",children:[(0,e.jsx)(n.a,{href:\"#getting-started-with-llm-engineering\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Getting Started with LLM Engineering\"]}),(0,e.jsxs)(n.p,{children:[\"I've been diving into the world of Large Language Model (LLM) engineering through an excellent \",(0,e.jsx)(n.a,{href:\"https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/\",children:\"Udemy course\"}),\" led by industry veteran Ed Donner. This comprehensive program takes you through real-world projects that demonstrate practical applications of AI technology in business scenarios.\"]}),(0,e.jsx)(n.p,{children:\"Currently about 25% through the course, I've already had hands-on experience with multiple AI platforms including OpenAI, Anthropic, and locally running models like Ollama. The course covers advanced techniques such as RAG (Retrieval-Augmented Generation), QLoRA (Quantized Low-Rank Adaptation), and AI Agents - all essential tools in the modern AI developer's toolkit.\"}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"the-flightai-assistant-project\",children:[(0,e.jsx)(n.a,{href:\"#the-flightai-assistant-project\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"The FlightAI Assistant Project\"]}),(0,e.jsxs)(n.p,{children:[\"One of the most engaging projects I completed was the \",(0,e.jsx)(n.strong,{children:\"AI-powered customer support assistant\"}),\" for a fictional airline called FlightAI. This project perfectly demonstrates how multiple AI services can work together to create a comprehensive user experience.\"]}),(0,e.jsx)(n.p,{children:\"The assistant leverages several cutting-edge AI models:\"}),(0,e.jsxs)(n.ul,{children:[(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"GPT-4o-mini\"}),\" for natural language chat interactions\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"DALL-E-3\"}),\" for generating images of destination cities\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"OpenAI's TTS-1\"}),\" for converting text responses to speech\"]})]}),(0,e.jsxs)(n.p,{children:[\"You can check out the complete project code in my \",(0,e.jsx)(n.a,{href:\"https://github.com/ryan-griego/ai-airline-assistant\",children:\"GitHub repository\"}),\".\"]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"discovering-gradio-for-rapid-prototyping\",children:[(0,e.jsx)(n.a,{href:\"#discovering-gradio-for-rapid-prototyping\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Discovering Gradio for Rapid Prototyping\"]}),(0,e.jsxs)(n.p,{children:[\"One of the most valuable tools introduced in the course is \",(0,e.jsx)(n.strong,{children:\"Gradio\"}),\", an open-source Python library that's a game-changer for AI developers. Gradio enables you to quickly build user-friendly web interfaces for AI models, APIs, or any Python function with minimal code.\"]}),(0,e.jsx)(n.p,{children:\"What makes Gradio particularly appealing is its ability to:\"}),(0,e.jsxs)(n.ul,{children:[(0,e.jsx)(n.li,{children:\"Create professional-looking demos in minutes\"}),(0,e.jsx)(n.li,{children:\"Generate live URLs for instant sharing\"}),(0,e.jsx)(n.li,{children:\"Provide an intuitive interface without requiring web development expertise\"})]}),(0,e.jsx)(n.p,{children:\"The speed at which you can go from a working AI model to a shareable web application is truly impressive.\"}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"development-environment-and-setup\",children:[(0,e.jsx)(n.a,{href:\"#development-environment-and-setup\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Development Environment and Setup\"]}),(0,e.jsx)(n.p,{children:\"The course utilizes a robust development stack:\"}),(0,e.jsxs)(n.ul,{children:[(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Anaconda\"}),\" platform for managing Python environments and dependencies\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Jupyter Lab\"}),\" as the primary development environment for working with notebooks, code, and data\"]})]}),(0,e.jsx)(n.p,{children:\"While the course materials use Jupyter notebooks, I decided to export my project to a standalone Python file. This approach gave me more flexibility to run the application outside of the Jupyter platform and better understand the underlying code structure.\"}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"learning-about-function-calling-with-llms\",children:[(0,e.jsx)(n.a,{href:\"#learning-about-function-calling-with-llms\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Learning About Function Calling with LLMs\"]}),(0,e.jsxs)(n.p,{children:[\"One of the most fascinating concepts I encountered was the ability to extend LLM capabilities through \",(0,e.jsx)(n.strong,{children:\"function calling\"}),\". This technique allows the AI model to execute custom functions as part of its response generation process.\"]}),(0,e.jsx)(n.p,{children:\"In the airline assistant project, I implemented this by:\"}),(0,e.jsxs)(n.ol,{children:[(0,e.jsxs)(n.li,{children:[\"Creating custom functions (like \",(0,e.jsx)(n.code,{children:\"get_ticket_price\"}),\")\"]}),(0,e.jsx)(n.li,{children:\"Passing these functions as tools to the chat completions API\"}),(0,e.jsx)(n.li,{children:\"Allowing the LLM to intelligently decide when to call these functions\"})]}),(0,e.jsxs)(n.p,{children:[\"For example, when a user asks about ticket prices, the LLM automatically triggers the \",(0,e.jsx)(n.code,{children:\"get_ticket_price\"}),\" function, which searches through a dictionary of city names and prices to return accurate pricing information. This seamless integration of custom logic with AI responses creates a much more powerful and practical application.\"]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"conclusion\",children:[(0,e.jsx)(n.a,{href:\"#conclusion\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Conclusion\"]}),(0,e.jsx)(n.p,{children:\"The combination of powerful AI models, intuitive development tools like Gradio, and techniques like function calling opens up endless possibilities for creating practical AI applications.\"}),(0,e.jsx)(n.p,{children:\"The experience of building a multi-modal AI assistant that can chat, generate images, and speak has given me a solid foundation for tackling more complex projects as I continue through the course. I'm excited to explore the remaining 75% of the curriculum and see what other innovative applications I can build.\"}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"sources\",children:[(0,e.jsx)(n.a,{href:\"#sources\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Sources\"]}),(0,e.jsxs)(n.ul,{children:[(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"https://github.com/ryan-griego/ai-airline-assistant\",children:\"AI Airline Assistant GitHub Repo\"})}),(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/\",children:\"Udemy Course\"})})]})]})}function d(i={}){let{wrapper:n}=i.components||{};return n?(0,e.jsx)(n,{...i,children:(0,e.jsx)(h,{...i})}):h(i)}return x(b);})();\n;return Component;"
  },
  "_id": "posts/building-ai-tools-with-llms-and-gradio.mdx",
  "_raw": {
    "sourceFilePath": "posts/building-ai-tools-with-llms-and-gradio.mdx",
    "sourceFileName": "building-ai-tools-with-llms-and-gradio.mdx",
    "sourceFileDir": "posts",
    "contentType": "mdx",
    "flattenedPath": "posts/building-ai-tools-with-llms-and-gradio"
  },
  "type": "Blog",
  "readingTime": {
    "text": "3 min read",
    "minutes": 2.88,
    "time": 172800,
    "words": 576
  },
  "slug": "building-ai-tools-with-llms-and-gradio",
  "path": "posts/building-ai-tools-with-llms-and-gradio",
  "filePath": "posts/building-ai-tools-with-llms-and-gradio.mdx",
  "toc": [
    {
      "value": "Getting Started with LLM Engineering",
      "url": "#getting-started-with-llm-engineering-3",
      "depth": 2
    },
    {
      "value": "The FlightAI Assistant Project",
      "url": "#the-flightai-assistant-project-3",
      "depth": 2
    },
    {
      "value": "Discovering Gradio for Rapid Prototyping",
      "url": "#discovering-gradio-for-rapid-prototyping-3",
      "depth": 2
    },
    {
      "value": "Development Environment and Setup",
      "url": "#development-environment-and-setup-3",
      "depth": 2
    },
    {
      "value": "Learning About Function Calling with LLMs",
      "url": "#learning-about-function-calling-with-llms-3",
      "depth": 2
    },
    {
      "value": "Conclusion",
      "url": "#conclusion-6",
      "depth": 2
    },
    {
      "value": "Sources",
      "url": "#sources-6",
      "depth": 2
    }
  ],
  "structuredData": {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Building AI Tools with LLMs and Gradio",
    "datePublished": "2025-06-18T07:00:00.000Z",
    "dateModified": "2025-06-18T07:00:00.000Z",
    "description": "This project is an AI-powered customer support assistant for a fictional airline called FlightAI. It leverages language models (like GPT-4o-mini) for chat interactions, DALL-E-3 for image generation (e.g., of destination cities), and OpenAI's text-to-speech model for audio responses. The user interface is built with Gradio.",
    "image": "/static/images/twitter-card.png",
    "url": "https://ryangriego.com/blog/posts/building-ai-tools-with-llms-and-gradio"
  }
}