{
  "title": "Building an AI Career Assistant: Context-Driven Professional Representation Without RAG",
  "date": "2025-10-16T00:00:00.000Z",
  "tags": [
    "AI",
    "Python",
    "OpenAI",
    "Gradio",
    "LLM",
    "Function Calling",
    "Pushover"
  ],
  "draft": false,
  "summary": "How I built an intelligent chatbot to represent my professional brand on my website using context injection, structured outputs, and an evaluator LLMâ€”all without needing vector databases or RAG.",
  "body": {
    "raw": "\n*A practical approach to building an AI assistant that accurately answers questions about your career, skills, and projects by leveraging prompt engineering and quality control systems.*\n\n---\n\n<div style={{textAlign: 'center', margin: '2rem 0', padding: '1.5rem', backgroundColor: '#f8f9fa', borderRadius: '8px', border: '2px solid #e9ecef'}}>\n  <h3 style={{margin: '0 0 1rem 0', color: '#495057'}}>ðŸ¤– Try the AI Career Assistant</h3>\n  <p style={{margin: '0 0 1rem 0', color: '#6c757d'}}>Experience the chatbot described in this article</p>\n  <a href=\"https://ryangriego.com/chat\" target=\"_blank\" rel=\"noopener noreferrer\" style={{display: 'inline-block', backgroundColor: '#007bff', color: 'white', padding: '12px 24px', textDecoration: 'none', borderRadius: '6px', fontWeight: '600'}}>Chat Now â†’</a>\n</div>\n\n## The Challenge\n\nAs a full-stack engineer with a diverse portfolio of projects, I wanted a way to help visitors to my website learn about my professional background without requiring manual responses to every inquiry. The challenge was creating an AI system that could:\n\n1. **Accurately represent my experience** without hallucinating fake companies or projects\n2. **Maintain professionalism** in all interactions\n3. **Facilitate meaningful connections** with potential employers or collaborators\n4. **Stay grounded in factual information** from my resume and LinkedIn profile\n\nTraditional chatbots either provide generic responses or require constant maintenance. I needed something smarterâ€”an autonomous representative that could handle professional inquiries while maintaining accuracy and facilitating genuine opportunities.\n\n## Why Didn't I Use RAG?\n\nMany AI assistant projects jump straight to Retrieval-Augmented Generation (RAG) with vector databases. But RAG adds complexity:\n- **Infrastructure overhead**: Vector databases, embeddings, similarity search\n- **Latency concerns**: Additional retrieval step before generation\n- **Maintenance burden**: Keeping embeddings updated\n\nFor a career assistant with relatively stable, focused information (resume, LinkedIn profile, GitHub repos), I realized **context injection was sufficient**. By including my professional documents directly in the system prompt, the LLM has all necessary information without additional retrieval steps.\n\n## The Solution\n\n**1. Context-Driven Prompts**\nInstead of RAG, I inject full context directly:\n```python\n# Professional documents included in every request\n- Resume (full text from PDF)\n- LinkedIn Profile (complete profile data)\n- Professional Summary\n- GitHub Integration (via API when needed)\n```\n\n**2. Evaluator LLM System**\nA secondary LLM validates every response for Accuracy, Professionalism, Completeness, and Hallucination Detection.\n\n**3. Structured Outputs**\nUsing OpenAI's structured output feature ensures consistent evaluation:\n```json\n{\n  \"evaluation\": \"PASS\" | \"FAIL\",\n  \"reasoning\": \"string\",\n  \"feedback\": \"string\"\n}\n```\n\n**4. Smart Function Calling**\nThe LLM can trigger specific actions:\n- `record_user_details`: Capture contact info for follow-up\n- `evaluate_job_match`: Analyze role fit\n- `search_github_repos`: Showcase technical projects\n- `send_push_notification`: Alert me to unknown questions\n\n## Key Features\n\n### 1. Context Injection Over RAG\n\nThe system loads professional documents once at startup:\n\n```python\n# Document loading\nresume = load_pdf('resume.pdf')\nlinkedin = load_pdf('linkedin.pdf')\nsummary = load_text('summary.txt')\n\n# Injected into every system prompt\nsystem_prompt = f\"\"\"\nYou are an AI assistant representing Ryan Griego.\n\n## CONTEXT:\nResume: {resume}\nLinkedIn: {linkedin}\nSummary: {summary}\n\nAnswer questions accurately based on this context.\n\"\"\"\n```\n\n**Benefits:**\n- No vector database infrastructure\n- Lower latency (no retrieval step)\n- Simpler deployment and maintenance\n- Complete context always available\n\n### 2. Dual-LLM Evaluation System\n\nEvery response goes through a validation layer to ensure accuracy and professionalism. The main LLM (GPT-4o-mini) processes user questions and generates responses, while a second evaluator LLM validates each response against the provided context, checking for hallucinations and ensuring professional tone. If issues are detected, the system triggers regeneration.\n\nThis dual-validation approach caught critical errors like incorrectly claiming work at companies not in my resume, fabricating project details, and confusing professional vs. personal questions. By implementing this validation layer, I ensured every response maintains high standards of accuracy while protecting my professional reputation.\n\n### 3. Intelligent Function Calling\n\nThe system uses OpenAI's function calling for specific capabilities:\n\n**GitHub Integration:**\n```python\ndef search_github_repos():\n    \"\"\"Fetches real-time GitHub repository data\"\"\"\n    repos = github_api.get_user_repos('ryan-griego')\n    return formatted_repo_list\n```\n\nWhen a user asks about my projects, the LLM can call this function to provide current information beyond what's in the resume.\n\n### 4. Push Notifications via Pushover\n\nOne of my favorite featuresâ€”when the chatbot encounters questions it can't answer, it sends me instant mobile notifications:\n\n### 5. Template-Based Prompt Management\n\nRather than hardcoding prompts, I use markdown templates:\n\n```\nprompts/\nâ”œâ”€â”€ chat_init.md      # Initial system prompt\nâ”œâ”€â”€ chat_base.md      # Base conversational rules\nâ”œâ”€â”€ evaluator.md      # Evaluation criteria\nâ””â”€â”€ job_match.md      # Job analysis prompt\n```\n\n## Deployment: Hugging Face Spaces\n\nI deployed on Hugging Face Spaces for:\n- Free hosting (with reasonable usage limits)\n- Automatic HTTPS\n- Easy environment variable management\n- Simple iframe embedding\n\nThe chatbot runs 24/7, ready to answer questions from potential employers or collaborators visiting my website.\n\n## Lessons Learned\n\n- **Don't Over-Engineer**: Context injection was sufficient instead of complex RAG systemsâ€”easier to build, maintain, and deploy\n- **Mobile Notifications Are Powerful**: Pushover integration ($5) provides real-time insights, opportunity awareness, and system monitoring\n- **Prompt Engineering Still Matters**: Careful prompt design prevents misclassification, inappropriate refusals, and tone inconsistencies\n\n## Future Enhancements\n\nThe modular architecture enables exciting possibilities:\n\n- **Conversation Memory**: Track previous questions in session, provide contextual follow-up responses, build on earlier conversation threads\n- **Advanced Analytics**: Question categorization and trending, user engagement metrics, conversion tracking for opportunities\n- **Multi-Language Support**: Automatic translation of responses, broader reach for international opportunities\n- **Video Integration**: Link to project demos and presentations, richer media responses for complex topics\n\n## Conclusion\n\nI created a system that accurately represents my professional brand while facilitating meaningful connections with potential employers and collaborators.\n\nThe project proves that sometimes the best solution isn't the most complexâ€”it's the one that solves the core problem efficiently and reliably. Context-driven chatbots with quality control can provide tremendous value without the overhead of vector databases and retrieval systems.\n\nFor professionals looking to enhance their online presence and automate career inquiries, this approach offers a practical, maintainable, and effective solution that runs autonomously while maintaining accuracy and professionalism.\n\n---\n\n## Technical Stack Summary\n\n**AI Models:** GPT-4o-mini (main LLM and evaluator)\n\n**Infrastructure:** Hugging Face Spaces, GitHub\n\n**Interface:** Gradio\n\n**Notifications:** Pushover\n\n**Languages:** Python\n\n**Key Libraries:** openai, gradio, pypdf, python-dotenv, requests\n\n**Deployment:** Hugging Face Spaces (free tier)\n\n---\n\n<div style={{textAlign: 'center', margin: '2rem 0', padding: '1.5rem', backgroundColor: '#f8f9fa', borderRadius: '8px', border: '2px solid #e9ecef'}}>\n  <h3 style={{margin: '0 0 1rem 0', color: '#495057'}}>ðŸš€ Ready to Try It?</h3>\n  <p style={{margin: '0 0 1rem 0', color: '#6c757d'}}>Test the AI Career Assistant for yourself</p>\n  <a href=\"https://ryangriego.com/chat\" target=\"_blank\" rel=\"noopener noreferrer\" style={{display: 'inline-block', backgroundColor: '#007bff', color: 'white', padding: '12px 24px', textDecoration: 'none', borderRadius: '6px', fontWeight: '600'}}>Start Chatting â†’</a>\n</div>\n\n## Sources\n\n[GitHub Repo](https://github.com/ryan-griego/ai-career-assistant-chatbot)\n\n[Gradio](https://www.gradio.app/)\n\n[OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)\n\n[Pushover](https://pushover.net/)\n\n[Hugging Face Spaces](https://huggingface.co/spaces)\n",
    "code": "var Component=(()=>{var p=Object.create;var l=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,N=Object.prototype.hasOwnProperty;var f=(a,n)=>()=>(n||a((n={exports:{}}).exports,n),n.exports),k=(a,n)=>{for(var s in n)l(a,s,{get:n[s],enumerable:!0})},r=(a,n,s,t)=>{if(n&&typeof n==\"object\"||typeof n==\"function\")for(let i of u(n))!N.call(a,i)&&i!==s&&l(a,i,{get:()=>n[i],enumerable:!(t=m(n,i))||t.enumerable});return a};var y=(a,n,s)=>(s=a!=null?p(g(a)):{},r(n||!a||!a.__esModule?l(s,\"default\",{value:a,enumerable:!0}):s,a)),w=a=>r(l({},\"__esModule\",{value:!0}),a);var o=f((I,c)=>{c.exports=_jsx_runtime});var b={};k(b,{default:()=>h,frontmatter:()=>v});var e=y(o()),v={title:\"Building an AI Career Assistant: Context-Driven Professional Representation Without RAG\",date:\"2025-10-16\",tags:[\"AI\",\"Python\",\"OpenAI\",\"Gradio\",\"LLM\",\"Function Calling\",\"Pushover\"],draft:!1,summary:\"How I built an intelligent chatbot to represent my professional brand on my website using context injection, structured outputs, and an evaluator LLM\\u2014all without needing vector databases or RAG.\"};function d(a){let n={a:\"a\",code:\"code\",em:\"em\",h2:\"h2\",h3:\"h3\",hr:\"hr\",li:\"li\",ol:\"ol\",p:\"p\",path:\"path\",pre:\"pre\",span:\"span\",strong:\"strong\",svg:\"svg\",ul:\"ul\",...a.components};return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(n.p,{children:(0,e.jsx)(n.em,{children:\"A practical approach to building an AI assistant that accurately answers questions about your career, skills, and projects by leveraging prompt engineering and quality control systems.\"})}),(0,e.jsx)(n.hr,{}),(0,e.jsxs)(\"div\",{style:{textAlign:\"center\",margin:\"2rem 0\",padding:\"1.5rem\",backgroundColor:\"#f8f9fa\",borderRadius:\"8px\",border:\"2px solid #e9ecef\"},children:[(0,e.jsx)(\"h3\",{style:{margin:\"0 0 1rem 0\",color:\"#495057\"},children:\"\\u{1F916} Try the AI Career Assistant\"}),(0,e.jsx)(\"p\",{style:{margin:\"0 0 1rem 0\",color:\"#6c757d\"},children:\"Experience the chatbot described in this article\"}),(0,e.jsx)(\"a\",{href:\"https://ryangriego.com/chat\",target:\"_blank\",rel:\"noopener noreferrer\",style:{display:\"inline-block\",backgroundColor:\"#007bff\",color:\"white\",padding:\"12px 24px\",textDecoration:\"none\",borderRadius:\"6px\",fontWeight:\"600\"},children:\"Chat Now \\u2192\"})]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"the-challenge\",children:[(0,e.jsx)(n.a,{href:\"#the-challenge\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"The Challenge\"]}),(0,e.jsx)(n.p,{children:\"As a full-stack engineer with a diverse portfolio of projects, I wanted a way to help visitors to my website learn about my professional background without requiring manual responses to every inquiry. The challenge was creating an AI system that could:\"}),(0,e.jsxs)(n.ol,{children:[(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Accurately represent my experience\"}),\" without hallucinating fake companies or projects\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Maintain professionalism\"}),\" in all interactions\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Facilitate meaningful connections\"}),\" with potential employers or collaborators\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Stay grounded in factual information\"}),\" from my resume and LinkedIn profile\"]})]}),(0,e.jsx)(n.p,{children:\"Traditional chatbots either provide generic responses or require constant maintenance. I needed something smarter\\u2014an autonomous representative that could handle professional inquiries while maintaining accuracy and facilitating genuine opportunities.\"}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"why-didnt-i-use-rag\",children:[(0,e.jsx)(n.a,{href:\"#why-didnt-i-use-rag\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Why Didn't I Use RAG?\"]}),(0,e.jsx)(n.p,{children:\"Many AI assistant projects jump straight to Retrieval-Augmented Generation (RAG) with vector databases. But RAG adds complexity:\"}),(0,e.jsxs)(n.ul,{children:[(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Infrastructure overhead\"}),\": Vector databases, embeddings, similarity search\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Latency concerns\"}),\": Additional retrieval step before generation\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Maintenance burden\"}),\": Keeping embeddings updated\"]})]}),(0,e.jsxs)(n.p,{children:[\"For a career assistant with relatively stable, focused information (resume, LinkedIn profile, GitHub repos), I realized \",(0,e.jsx)(n.strong,{children:\"context injection was sufficient\"}),\". By including my professional documents directly in the system prompt, the LLM has all necessary information without additional retrieval steps.\"]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"the-solution\",children:[(0,e.jsx)(n.a,{href:\"#the-solution\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"The Solution\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"1. Context-Driven Prompts\"}),\" Instead of RAG, I inject full context directly:\"]}),(0,e.jsx)(n.pre,{className:\"language-python\",children:(0,e.jsxs)(n.code,{className:\"language-python code-highlight\",children:[(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token comment\",children:\"# Professional documents included in every request\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token operator\",children:\"-\"}),\" Resume \",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),\"full text \",(0,e.jsx)(n.span,{className:\"token keyword\",children:\"from\"}),\" PDF\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token operator\",children:\"-\"}),\" LinkedIn Profile \",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),\"complete profile data\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token operator\",children:\"-\"}),` Professional Summary\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token operator\",children:\"-\"}),\" GitHub Integration \",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),\"via API when needed\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"2. Evaluator LLM System\"}),\" A secondary LLM validates every response for Accuracy, Professionalism, Completeness, and Hallucination Detection.\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"3. Structured Outputs\"}),\" Using OpenAI's structured output feature ensures consistent evaluation:\"]}),(0,e.jsx)(n.pre,{className:\"language-json\",children:(0,e.jsxs)(n.code,{className:\"code-highlight language-json\",children:[(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"{\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"  \",(0,e.jsx)(n.span,{className:\"token property\",children:'\"evaluation\"'}),(0,e.jsx)(n.span,{className:\"token operator\",children:\":\"}),\" \",(0,e.jsx)(n.span,{className:\"token string\",children:'\"PASS\"'}),\" | \",(0,e.jsx)(n.span,{className:\"token string\",children:'\"FAIL\"'}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\",\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"  \",(0,e.jsx)(n.span,{className:\"token property\",children:'\"reasoning\"'}),(0,e.jsx)(n.span,{className:\"token operator\",children:\":\"}),\" \",(0,e.jsx)(n.span,{className:\"token string\",children:'\"string\"'}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\",\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"  \",(0,e.jsx)(n.span,{className:\"token property\",children:'\"feedback\"'}),(0,e.jsx)(n.span,{className:\"token operator\",children:\":\"}),\" \",(0,e.jsx)(n.span,{className:\"token string\",children:'\"string\"'}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"}\"}),`\n`]})]})}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"4. Smart Function Calling\"}),\" The LLM can trigger specific actions:\"]}),(0,e.jsxs)(n.ul,{children:[(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.code,{children:\"record_user_details\"}),\": Capture contact info for follow-up\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.code,{children:\"evaluate_job_match\"}),\": Analyze role fit\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.code,{children:\"search_github_repos\"}),\": Showcase technical projects\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.code,{children:\"send_push_notification\"}),\": Alert me to unknown questions\"]})]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"key-features\",children:[(0,e.jsx)(n.a,{href:\"#key-features\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Key Features\"]}),(0,e.jsxs)(n.h3,{className:\"content-header\",id:\"1-context-injection-over-rag\",children:[(0,e.jsx)(n.a,{href:\"#1-context-injection-over-rag\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"1. Context Injection Over RAG\"]}),(0,e.jsx)(n.p,{children:\"The system loads professional documents once at startup:\"}),(0,e.jsx)(n.pre,{className:\"language-python\",children:(0,e.jsxs)(n.code,{className:\"language-python code-highlight\",children:[(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token comment\",children:\"# Document loading\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"resume \",(0,e.jsx)(n.span,{className:\"token operator\",children:\"=\"}),\" load_pdf\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),(0,e.jsx)(n.span,{className:\"token string\",children:\"'resume.pdf'\"}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"linkedin \",(0,e.jsx)(n.span,{className:\"token operator\",children:\"=\"}),\" load_pdf\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),(0,e.jsx)(n.span,{className:\"token string\",children:\"'linkedin.pdf'\"}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"summary \",(0,e.jsx)(n.span,{className:\"token operator\",children:\"=\"}),\" load_text\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),(0,e.jsx)(n.span,{className:\"token string\",children:\"'summary.txt'\"}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,e.jsx)(n.span,{className:\"code-line\",children:`\n`}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token comment\",children:\"# Injected into every system prompt\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"system_prompt \",(0,e.jsx)(n.span,{className:\"token operator\",children:\"=\"}),\" \",(0,e.jsx)(n.span,{className:\"token string-interpolation\",children:(0,e.jsx)(n.span,{className:\"token string\",children:`f\"\"\"\n`})})]}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsx)(n.span,{className:\"token string-interpolation\",children:(0,e.jsx)(n.span,{className:\"token string\",children:`You are an AI assistant representing Ryan Griego.\n`})})}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsx)(n.span,{className:\"token string-interpolation\",children:(0,e.jsx)(n.span,{className:\"token string\",children:`\n`})})}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsx)(n.span,{className:\"token string-interpolation\",children:(0,e.jsx)(n.span,{className:\"token string\",children:`## CONTEXT:\n`})})}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsxs)(n.span,{className:\"token string-interpolation\",children:[(0,e.jsx)(n.span,{className:\"token string\",children:\"Resume: \"}),(0,e.jsxs)(n.span,{className:\"token interpolation\",children:[(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"{\"}),\"resume\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"}\"})]}),(0,e.jsx)(n.span,{className:\"token string\",children:`\n`})]})}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsxs)(n.span,{className:\"token string-interpolation\",children:[(0,e.jsx)(n.span,{className:\"token string\",children:\"LinkedIn: \"}),(0,e.jsxs)(n.span,{className:\"token interpolation\",children:[(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"{\"}),\"linkedin\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"}\"})]}),(0,e.jsx)(n.span,{className:\"token string\",children:`\n`})]})}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsxs)(n.span,{className:\"token string-interpolation\",children:[(0,e.jsx)(n.span,{className:\"token string\",children:\"Summary: \"}),(0,e.jsxs)(n.span,{className:\"token interpolation\",children:[(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"{\"}),\"summary\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"}\"})]}),(0,e.jsx)(n.span,{className:\"token string\",children:`\n`})]})}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsx)(n.span,{className:\"token string-interpolation\",children:(0,e.jsx)(n.span,{className:\"token string\",children:`\n`})})}),(0,e.jsx)(n.span,{className:\"code-line\",children:(0,e.jsx)(n.span,{className:\"token string-interpolation\",children:(0,e.jsx)(n.span,{className:\"token string\",children:`Answer questions accurately based on this context.\n`})})}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token string-interpolation\",children:(0,e.jsx)(n.span,{className:\"token string\",children:'\"\"\"'})}),`\n`]})]})}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.strong,{children:\"Benefits:\"})}),(0,e.jsxs)(n.ul,{children:[(0,e.jsx)(n.li,{children:\"No vector database infrastructure\"}),(0,e.jsx)(n.li,{children:\"Lower latency (no retrieval step)\"}),(0,e.jsx)(n.li,{children:\"Simpler deployment and maintenance\"}),(0,e.jsx)(n.li,{children:\"Complete context always available\"})]}),(0,e.jsxs)(n.h3,{className:\"content-header\",id:\"2-dual-llm-evaluation-system\",children:[(0,e.jsx)(n.a,{href:\"#2-dual-llm-evaluation-system\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"2. Dual-LLM Evaluation System\"]}),(0,e.jsx)(n.p,{children:\"Every response goes through a validation layer to ensure accuracy and professionalism. The main LLM (GPT-4o-mini) processes user questions and generates responses, while a second evaluator LLM validates each response against the provided context, checking for hallucinations and ensuring professional tone. If issues are detected, the system triggers regeneration.\"}),(0,e.jsx)(n.p,{children:\"This dual-validation approach caught critical errors like incorrectly claiming work at companies not in my resume, fabricating project details, and confusing professional vs. personal questions. By implementing this validation layer, I ensured every response maintains high standards of accuracy while protecting my professional reputation.\"}),(0,e.jsxs)(n.h3,{className:\"content-header\",id:\"3-intelligent-function-calling\",children:[(0,e.jsx)(n.a,{href:\"#3-intelligent-function-calling\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"3. Intelligent Function Calling\"]}),(0,e.jsx)(n.p,{children:\"The system uses OpenAI's function calling for specific capabilities:\"}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.strong,{children:\"GitHub Integration:\"})}),(0,e.jsx)(n.pre,{className:\"language-python\",children:(0,e.jsxs)(n.code,{className:\"language-python code-highlight\",children:[(0,e.jsxs)(n.span,{className:\"code-line\",children:[(0,e.jsx)(n.span,{className:\"token keyword\",children:\"def\"}),\" \",(0,e.jsx)(n.span,{className:\"token function\",children:\"search_github_repos\"}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"    \",(0,e.jsx)(n.span,{className:\"token string triple-quoted-string\",children:'\"\"\"Fetches real-time GitHub repository data\"\"\"'}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"    repos \",(0,e.jsx)(n.span,{className:\"token operator\",children:\"=\"}),\" github_api\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\".\"}),\"get_user_repos\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\"(\"}),(0,e.jsx)(n.span,{className:\"token string\",children:\"'ryan-griego'\"}),(0,e.jsx)(n.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"    \",(0,e.jsx)(n.span,{className:\"token keyword\",children:\"return\"}),` formatted_repo_list\n`]})]})}),(0,e.jsx)(n.p,{children:\"When a user asks about my projects, the LLM can call this function to provide current information beyond what's in the resume.\"}),(0,e.jsxs)(n.h3,{className:\"content-header\",id:\"4-push-notifications-via-pushover\",children:[(0,e.jsx)(n.a,{href:\"#4-push-notifications-via-pushover\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"4. Push Notifications via Pushover\"]}),(0,e.jsx)(n.p,{children:\"One of my favorite features\\u2014when the chatbot encounters questions it can't answer, it sends me instant mobile notifications:\"}),(0,e.jsxs)(n.h3,{className:\"content-header\",id:\"5-template-based-prompt-management\",children:[(0,e.jsx)(n.a,{href:\"#5-template-based-prompt-management\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"5. Template-Based Prompt Management\"]}),(0,e.jsx)(n.p,{children:\"Rather than hardcoding prompts, I use markdown templates:\"}),(0,e.jsx)(n.pre,{className:\"language-js\",children:(0,e.jsxs)(n.code,{className:\"code-highlight language-js\",children:[(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"prompts\",(0,e.jsx)(n.span,{className:\"token operator\",children:\"/\"}),`\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"\\u251C\\u2500\\u2500 chat_init\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(n.span,{className:\"token property-access\",children:\"md\"}),\"      # \",(0,e.jsx)(n.span,{className:\"token maybe-class-name\",children:\"Initial\"}),` system prompt\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"\\u251C\\u2500\\u2500 chat_base\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(n.span,{className:\"token property-access\",children:\"md\"}),\"      # \",(0,e.jsx)(n.span,{className:\"token maybe-class-name\",children:\"Base\"}),` conversational rules\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"\\u251C\\u2500\\u2500 evaluator\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(n.span,{className:\"token property-access\",children:\"md\"}),\"      # \",(0,e.jsx)(n.span,{className:\"token maybe-class-name\",children:\"Evaluation\"}),` criteria\n`]}),(0,e.jsxs)(n.span,{className:\"code-line\",children:[\"\\u2514\\u2500\\u2500 job_match\",(0,e.jsx)(n.span,{className:\"token punctuation\",children:\".\"}),(0,e.jsx)(n.span,{className:\"token property-access\",children:\"md\"}),\"      # \",(0,e.jsx)(n.span,{className:\"token maybe-class-name\",children:\"Job\"}),` analysis prompt\n`]})]})}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"deployment-hugging-face-spaces\",children:[(0,e.jsx)(n.a,{href:\"#deployment-hugging-face-spaces\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Deployment: Hugging Face Spaces\"]}),(0,e.jsx)(n.p,{children:\"I deployed on Hugging Face Spaces for:\"}),(0,e.jsxs)(n.ul,{children:[(0,e.jsx)(n.li,{children:\"Free hosting (with reasonable usage limits)\"}),(0,e.jsx)(n.li,{children:\"Automatic HTTPS\"}),(0,e.jsx)(n.li,{children:\"Easy environment variable management\"}),(0,e.jsx)(n.li,{children:\"Simple iframe embedding\"})]}),(0,e.jsx)(n.p,{children:\"The chatbot runs 24/7, ready to answer questions from potential employers or collaborators visiting my website.\"}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"lessons-learned\",children:[(0,e.jsx)(n.a,{href:\"#lessons-learned\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Lessons Learned\"]}),(0,e.jsxs)(n.ul,{children:[(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Don't Over-Engineer\"}),\": Context injection was sufficient instead of complex RAG systems\\u2014easier to build, maintain, and deploy\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Mobile Notifications Are Powerful\"}),\": Pushover integration ($5) provides real-time insights, opportunity awareness, and system monitoring\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Prompt Engineering Still Matters\"}),\": Careful prompt design prevents misclassification, inappropriate refusals, and tone inconsistencies\"]})]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"future-enhancements\",children:[(0,e.jsx)(n.a,{href:\"#future-enhancements\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Future Enhancements\"]}),(0,e.jsx)(n.p,{children:\"The modular architecture enables exciting possibilities:\"}),(0,e.jsxs)(n.ul,{children:[(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Conversation Memory\"}),\": Track previous questions in session, provide contextual follow-up responses, build on earlier conversation threads\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Advanced Analytics\"}),\": Question categorization and trending, user engagement metrics, conversion tracking for opportunities\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Multi-Language Support\"}),\": Automatic translation of responses, broader reach for international opportunities\"]}),(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.strong,{children:\"Video Integration\"}),\": Link to project demos and presentations, richer media responses for complex topics\"]})]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"conclusion\",children:[(0,e.jsx)(n.a,{href:\"#conclusion\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Conclusion\"]}),(0,e.jsx)(n.p,{children:\"I created a system that accurately represents my professional brand while facilitating meaningful connections with potential employers and collaborators.\"}),(0,e.jsx)(n.p,{children:\"The project proves that sometimes the best solution isn't the most complex\\u2014it's the one that solves the core problem efficiently and reliably. Context-driven chatbots with quality control can provide tremendous value without the overhead of vector databases and retrieval systems.\"}),(0,e.jsx)(n.p,{children:\"For professionals looking to enhance their online presence and automate career inquiries, this approach offers a practical, maintainable, and effective solution that runs autonomously while maintaining accuracy and professionalism.\"}),(0,e.jsx)(n.hr,{}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"technical-stack-summary\",children:[(0,e.jsx)(n.a,{href:\"#technical-stack-summary\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Technical Stack Summary\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"AI Models:\"}),\" GPT-4o-mini (main LLM and evaluator)\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"Infrastructure:\"}),\" Hugging Face Spaces, GitHub\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"Interface:\"}),\" Gradio\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"Notifications:\"}),\" Pushover\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"Languages:\"}),\" Python\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"Key Libraries:\"}),\" openai, gradio, pypdf, python-dotenv, requests\"]}),(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"Deployment:\"}),\" Hugging Face Spaces (free tier)\"]}),(0,e.jsx)(n.hr,{}),(0,e.jsxs)(\"div\",{style:{textAlign:\"center\",margin:\"2rem 0\",padding:\"1.5rem\",backgroundColor:\"#f8f9fa\",borderRadius:\"8px\",border:\"2px solid #e9ecef\"},children:[(0,e.jsx)(\"h3\",{style:{margin:\"0 0 1rem 0\",color:\"#495057\"},children:\"\\u{1F680} Ready to Try It?\"}),(0,e.jsx)(\"p\",{style:{margin:\"0 0 1rem 0\",color:\"#6c757d\"},children:\"Test the AI Career Assistant for yourself\"}),(0,e.jsx)(\"a\",{href:\"https://ryangriego.com/chat\",target:\"_blank\",rel:\"noopener noreferrer\",style:{display:\"inline-block\",backgroundColor:\"#007bff\",color:\"white\",padding:\"12px 24px\",textDecoration:\"none\",borderRadius:\"6px\",fontWeight:\"600\"},children:\"Start Chatting \\u2192\"})]}),(0,e.jsxs)(n.h2,{className:\"content-header\",id:\"sources\",children:[(0,e.jsx)(n.a,{href:\"#sources\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(e.Fragment,{children:(0,e.jsx)(n.span,{className:\"content-header-link\",children:(0,e.jsxs)(n.svg,{className:\"h-5 linkicon w-5\",fill:\"currentColor\",viewBox:\"0 0 20 20\",xmlns:\"http://www.w3.org/2000/svg\",children:[(0,e.jsx)(n.path,{d:\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}),(0,e.jsx)(n.path,{d:\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"})]})})})}),\"Sources\"]}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://github.com/ryan-griego/ai-career-assistant-chatbot\",children:\"GitHub Repo\"})}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://www.gradio.app/\",children:\"Gradio\"})}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://platform.openai.com/docs/guides/function-calling\",children:\"OpenAI Function Calling\"})}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://pushover.net/\",children:\"Pushover\"})}),(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://huggingface.co/spaces\",children:\"Hugging Face Spaces\"})})]})}function h(a={}){let{wrapper:n}=a.components||{};return n?(0,e.jsx)(n,{...a,children:(0,e.jsx)(d,{...a})}):d(a)}return w(b);})();\n;return Component;"
  },
  "_id": "posts/career-assistant-ai-chatbot-project.mdx",
  "_raw": {
    "sourceFilePath": "posts/career-assistant-ai-chatbot-project.mdx",
    "sourceFileName": "career-assistant-ai-chatbot-project.mdx",
    "sourceFileDir": "posts",
    "contentType": "mdx",
    "flattenedPath": "posts/career-assistant-ai-chatbot-project"
  },
  "type": "Blog",
  "readingTime": {
    "text": "6 min read",
    "minutes": 5.375,
    "time": 322500,
    "words": 1075
  },
  "slug": "career-assistant-ai-chatbot-project",
  "path": "posts/career-assistant-ai-chatbot-project",
  "filePath": "posts/career-assistant-ai-chatbot-project.mdx",
  "toc": [
    {
      "value": "The Challenge",
      "url": "#the-challenge-1",
      "depth": 2
    },
    {
      "value": "Why Didn't I Use RAG?",
      "url": "#why-didnt-i-use-rag",
      "depth": 2
    },
    {
      "value": "The Solution",
      "url": "#the-solution",
      "depth": 2
    },
    {
      "value": "Key Features",
      "url": "#key-features",
      "depth": 2
    },
    {
      "value": "1. Context Injection Over RAG",
      "url": "#1-context-injection-over-rag",
      "depth": 3
    },
    {
      "value": "2. Dual-LLM Evaluation System",
      "url": "#2-dual-llm-evaluation-system",
      "depth": 3
    },
    {
      "value": "3. Intelligent Function Calling",
      "url": "#3-intelligent-function-calling",
      "depth": 3
    },
    {
      "value": "4. Push Notifications via Pushover",
      "url": "#4-push-notifications-via-pushover",
      "depth": 3
    },
    {
      "value": "5. Template-Based Prompt Management",
      "url": "#5-template-based-prompt-management",
      "depth": 3
    },
    {
      "value": "Deployment: Hugging Face Spaces",
      "url": "#deployment-hugging-face-spaces",
      "depth": 2
    },
    {
      "value": "Lessons Learned",
      "url": "#lessons-learned-1",
      "depth": 2
    },
    {
      "value": "Future Enhancements",
      "url": "#future-enhancements-2",
      "depth": 2
    },
    {
      "value": "Conclusion",
      "url": "#conclusion-3",
      "depth": 2
    },
    {
      "value": "Technical Stack Summary",
      "url": "#technical-stack-summary-1",
      "depth": 2
    },
    {
      "value": "Sources",
      "url": "#sources-3",
      "depth": 2
    }
  ],
  "structuredData": {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Building an AI Career Assistant: Context-Driven Professional Representation Without RAG",
    "datePublished": "2025-10-16T00:00:00.000Z",
    "dateModified": "2025-10-16T00:00:00.000Z",
    "description": "How I built an intelligent chatbot to represent my professional brand on my website using context injection, structured outputs, and an evaluator LLMâ€”all without needing vector databases or RAG.",
    "image": "/static/images/twitter-card.png",
    "url": "https://ryangriego.com/blog/posts/career-assistant-ai-chatbot-project"
  }
}